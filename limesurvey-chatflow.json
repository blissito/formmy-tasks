{
  "nodes": [
    {
      "id": "conversationChain_0",
      "position": {
        "x": 491.36775445044134,
        "y": -85.40549138318039
      },
      "type": "customNode",
      "data": {
        "id": "conversationChain_0",
        "label": "Conversation Chain",
        "version": 3,
        "name": "conversationChain",
        "type": "ConversationChain",
        "baseClasses": [
          "ConversationChain",
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chat models specific conversational chain with memory",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "description": "If Chat Prompt Template is provided, this will be ignored",
            "additionalParams": true,
            "optional": true,
            "default": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
            "placeholder": "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.",
            "id": "conversationChain_0-input-systemMessagePrompt-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationChain_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "id": "conversationChain_0-input-memory-BaseMemory",
            "display": true
          },
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "optional": true,
            "id": "conversationChain_0-input-tools-Tool",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatAnthropic_0.data.instance}}",
          "memory": "{{bufferMemory_0.data.instance}}",
          "tools": ["{{customTool_0.data.instance}}"],
          "systemMessagePrompt": "Eres un asistente especializado en gestión de encuestas LimeSurvey.\n\nPuedes ayudar a:\n- Crear nuevas encuestas\n- Listar encuestas existentes\n- Eliminar encuestas\n- Obtener información detallada de encuestas\n\nCuando el usuario solicite alguna acción sobre encuestas, usa la herramienta 'limesurvey_cli' disponible.\n\nComandos disponibles:\n- Para listar: 'survey list'\n- Para crear: 'survey create \"Título de la Encuesta\"'\n- Para eliminar: 'survey delete ID --yes' \n- Para información: 'survey info ID'\n\nEjemplos:\n- \"Lista mis encuestas\" → usar limesurvey_cli con 'survey list'\n- \"Crea una encuesta de satisfacción\" → usar limesurvey_cli con 'survey create \"Encuesta de Satisfacción\"'\n- \"Elimina la encuesta 12345\" → usar limesurvey_cli con 'survey delete 12345 --yes'\n\nSiempre responde en español de manera clara y confirma las acciones realizadas."
        },
        "outputAnchors": [
          {
            "id": "conversationChain_0-output-conversationChain-ConversationChain|LLMChain|BaseChain|Runnable",
            "name": "conversationChain",
            "label": "ConversationChain",
            "description": "Chat models specific conversational chain with memory",
            "type": "ConversationChain | LLMChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 441,
      "selected": false,
      "positionAbsolute": {
        "x": 491.36775445044134,
        "y": -85.40549138318039
      },
      "dragging": false
    },
    {
      "id": "bufferMemory_0",
      "position": {
        "x": -4.966674308957906,
        "y": -174.5057730651327
      },
      "type": "customNode",
      "data": {
        "id": "bufferMemory_0",
        "label": "Buffer Memory",
        "version": 2,
        "name": "bufferMemory",
        "type": "BufferMemory",
        "baseClasses": [
          "BufferMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Retrieve chat messages stored in database",
        "inputParams": [
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "bufferMemory_0-input-sessionId-string",
            "display": true
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "bufferMemory_0-input-memoryKey-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "memoryKey": "chat_history"
        },
        "outputAnchors": [
          {
            "id": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
            "name": "bufferMemory",
            "label": "BufferMemory",
            "description": "Retrieve chat messages stored in database",
            "type": "BufferMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 259,
      "selected": false,
      "positionAbsolute": {
        "x": -4.966674308957906,
        "y": -174.5057730651327
      },
      "dragging": false
    },
    {
      "id": "chatAnthropic_0",
      "position": {
        "x": 6.673199402419982,
        "y": 103.666682078924
      },
      "type": "customNode",
      "data": {
        "id": "chatAnthropic_0",
        "label": "ChatAnthropic",
        "version": 8,
        "name": "chatAnthropic",
        "type": "ChatAnthropic",
        "baseClasses": [
          "ChatAnthropic",
          "ChatAnthropicMessages",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around ChatAnthropic large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "anthropicApi"
            ],
            "id": "chatAnthropic_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "claude-3-haiku",
            "id": "chatAnthropic_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatAnthropic_0-input-temperature-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatAnthropic_0-input-cache-BaseCache",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "claude-3-haiku-20240307",
          "temperature": "0.3",
          "streaming": true,
          "maxTokensToSample": "",
          "topP": "",
          "topK": "",
          "extendedThinking": "",
          "budgetTokens": 1024,
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatAnthropic_0-output-chatAnthropic-ChatAnthropic|ChatAnthropicMessages|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatAnthropic",
            "label": "ChatAnthropic",
            "description": "Wrapper around ChatAnthropic large language models that use the Chat endpoint",
            "type": "ChatAnthropic | ChatAnthropicMessages | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 676,
      "selected": false,
      "positionAbsolute": {
        "x": 6.673199402419982,
        "y": 103.666682078924
      },
      "dragging": false
    },
    {
      "id": "customTool_0",
      "position": {
        "x": 200,
        "y": 400
      },
      "type": "customNode",
      "data": {
        "id": "customTool_0",
        "label": "Custom Tool",
        "version": 1,
        "name": "customTool",
        "type": "CustomTool",
        "baseClasses": [
          "CustomTool",
          "Tool",
          "StructuredTool"
        ],
        "category": "Tools",
        "description": "Use custom tool you've created",
        "inputParams": [
          {
            "label": "Tool Name",
            "name": "name",
            "type": "string",
            "placeholder": "search_api",
            "id": "customTool_0-input-name-string",
            "display": true
          },
          {
            "label": "Tool Description",
            "name": "description",
            "type": "string",
            "rows": 3,
            "placeholder": "Call this to get the current weather",
            "id": "customTool_0-input-description-string",
            "display": true
          },
          {
            "label": "Tool Function",
            "name": "code",
            "type": "string",
            "rows": 6,
            "placeholder": "const func = async (query) => {\n    return query\n}\nreturn func",
            "id": "customTool_0-input-code-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "name": "limesurvey_cli",
          "description": "Ejecuta comandos del CLI de LimeSurvey para gestionar encuestas. Recibe un comando como parámetro (ej: 'survey list', 'survey create \"titulo\"', 'survey delete ID --yes', 'survey info ID')",
          "code": "const { exec } = require('child_process');\nconst util = require('util');\nconst execAsync = util.promisify(exec);\n\nconst func = async (command) => {\n    try {\n        console.log(`Ejecutando comando LimeSurvey: lime ${command}`);\n        \n        const { stdout, stderr } = await execAsync(`lime ${command}`);\n        \n        if (stderr && !stderr.includes('warn')) {\n            console.error('Error stderr:', stderr);\n            return `Error ejecutando comando: ${stderr}`;\n        }\n        \n        console.log('Comando ejecutado exitosamente:', stdout);\n        return stdout || 'Comando ejecutado exitosamente';\n        \n    } catch (error) {\n        console.error('Error ejecutando LimeSurvey CLI:', error);\n        return `Error: ${error.message}. Asegúrate de que el CLI de LimeSurvey esté instalado y configurado correctamente.`;\n    }\n};\n\nreturn func;"
        },
        "outputAnchors": [
          {
            "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool",
            "name": "customTool",
            "label": "Custom Tool",
            "description": "Use custom tool you've created",
            "type": "CustomTool | Tool | StructuredTool"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 508,
      "selected": false,
      "positionAbsolute": {
        "x": 200,
        "y": 400
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "bufferMemory_0",
      "sourceHandle": "bufferMemory_0-output-bufferMemory-BufferMemory|BaseChatMemory|BaseMemory",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-memory-BaseMemory",
      "type": "buttonedge",
      "id": "bufferMemory_0-conversationChain_0"
    },
    {
      "source": "chatAnthropic_0",
      "sourceHandle": "chatAnthropic_0-output-chatAnthropic-ChatAnthropic|ChatAnthropicMessages|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatAnthropic_0-conversationChain_0"
    },
    {
      "source": "customTool_0",
      "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool",
      "target": "conversationChain_0",
      "targetHandle": "conversationChain_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "customTool_0-conversationChain_0"
    }
  ]
}